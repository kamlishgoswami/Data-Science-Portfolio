# Data-Science-Portfolio

# [Project 1: Washignton House Prices Prediction: Project Overview](https://github.com/kamlishgoswami/Washington-House-Prices-Prediction/tree/main)

•	Downloaded real estate property dataset from Kaggle for Washington, USA.

•	Performed data preprocessing, including handling missing values, outliers, and encoding categorical variables 

•	Conducted feature engineering to create new meaningful features.

•	Performed exploratory data analysis (EDA) to gain insights and understand the data distribution and relationships.

•	Split the data into training and testing sets using a 75% training and 25% testing split.

•	Optimized Linear Regressor, Lasso Regressor, Decision Tree Regressor and Support Vector Regressor using GridSearchCV to reach the best model

•	Developed a client-facing API using FastAPI to provide real estate price predictions based on the deployed model.

•	Created a website using HTML, CSS, Bootstrap, and JavaScript to enhance user experience and interact with the API.

•	Deployed the model, API, and website to AWS for accessibility and scalability.

Technologies Used: Python, Numpy, Pandas Matplotlib, Seaborn, scikit-learn, Joblib, JSON, FastAPI, AWS, HTML,CSS,Bootstrap and JavaScript. 

[AWS Link](http://ec2-54-242-12-7.compute-1.amazonaws.com/)

![Website](Washigton%20House%20Prices%20Prediction.png)




# [Project 2: Image Classification: Project Overview](https://github.com/kamlishgoswami/Image-Classification-)

• Collected and prepared a diverse dataset by scraping images from Google using Selenium

• Utilized OpenCV for efficient data preprocessing, including face and eyes detection, to extract and crop facial regions from the images.

• Applied Wavelet transform for feature engineering and capturing important image details

• Split the data using Train Test Split for model evaluation

• Conducted extensive model optimization using GridSearchCV, exploring multiple classifiers including SVM, Random Forest, and Logistic Regression.

• Achieved exceptional accuracy of 95.4% on the dataset by identifying Support Vector Machine (SVM) as the best-performing classifier.

• Communicated findings effectively through comprehensive reports, including classification metrics such as precision, recall, and F1-score.

Technologies Used: Python, Numpy, Pandas Matplotlib, Seaborn, scikit-learn, OpenCV, PyWavelets, Joblib, JSON, Selenium

![Classification Report](Screenshot%202023-05-22%20at%207.38.35%20PM.png) ![Confusion Matrix](download.png) 
